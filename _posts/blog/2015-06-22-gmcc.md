---
layout: post
title: Generalised maximum correntropy criterion
excerpt: Robust correntropy based adaptive filtering for non-Gaussain signals
categories: blog
tags: [information theory, signal processing]
comments: true
---


Correntropy is a nonlinear and local similarity measure directly related to the probability of how similar two random variables are in a neighborhood of the joint space controlled by the kernel bandwidth of the estimator of the PDFs.

Correntropy has received increasing attention in domains of machine learning and signal processing as demonstrated by one of many papers recently submitted to the IEEE Transactions on Signal Processing:

> ... In this work, we propose a generalized correntropy that adopts the generalized Gaussian density (GGD) function as the kernel (not necessarily a Mercer kernel), and present some important properties. We further propose the generalized maximum correntropy criterion (GMCC), and apply it to adaptive filtering. An adaptive algorithm, called the GMCC algorithm, is derived, and the mean square convergence performance is studied. We show that the proposed algorithm is very stable and can achieve zero probability of divergence (POD). Simulation results confirm the theoretical expectations and demonstrate the desirable performance of the new algorithm. 

Link: [Generalized Correntropy for Robust Adaptive Filtering](http://arxiv.org/abs/1504.02931)

Key points to take away from the paper:

<figure class="half">
	<a href="/images/GMIC.png">      <img src="/images/GMIC.png"      alt="image"></a>
	<a href="/images/GMCC_conv.png"> <img src="/images/GMCC_conv.png" alt="image"></a>
	<figcaption> </figcaption>
</figure>


* The mean square error (MSE) criterion and variants of the least mean square (LMS) algorithm such as normalized LMS (NLMS) and variable step-size LMS (VSSLMS)  is widely used as a cost function since it has attractive features, such as smoothness, convexity, mathematical tractability, low computational burden and optimality under Gaussian assumption.

* The MSE criterion is sub-optimal when the Gaussain assumption does not hold for the signals being adapted, and an alternate criterion is sought.

* In recent years, the maximum correntropy criterion (MCC) has been successfully used in robust adaptive filtering, wherein the filter weights are adapted such that the correntropy between the desired signal and filter output is maximized.

* Since correntropy is insensitive to outliers especially with a small kernel bandwidth,  it is naturally a robust adaptation cost in presence of heavy-tailed impulsive noises.

* The optimal solution of GMCC filtering is in form similar to the well-known Wiener solution, except that the autocorrelation matrix and cross-correlation vector are weighted by an error nonlinearity. If the signals involved are zero-mean Gaussian, the optimal solution will equal to the Wiener solution.

* **Weight adaptation applies to the training of adaptive filters or neural networks, hence the relevance to machine learning.**