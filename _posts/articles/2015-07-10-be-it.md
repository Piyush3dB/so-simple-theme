---
layout: post
title: "Bayesian Inference in terms of Information Theory"
excerpt: "Information Theoretic analysis of Bayes’ rule"
categories: articles
tags: [signal processing, information theory, machine learning]
comments: true
share: true
---


Bayesian inference is a method of statistical inference in which Bayes' rule is used to update the likelihood for a Hypothesis as Evidence is acquired.

The Bayes' rule for inferring the likelihood of a Hypothesis given some Evidence is defined as:

$$
P(Hypothesis  \mid  Evidence) = \frac{ P(Hypothesis) P(Evidence \mid Hypothesis)} { P(Evidence)}
$$

or

$$
P(B  \mid  E) = \frac{ P(B) P(E \mid B)}{  P(E)}
$$


$$B$$ stands for Hypothesis (or Belief) and $$E$$ stands for Evidence. The rest of the terms are probabilities (or likelihoods):

* $$P(B \mid E)$$ is the posterior probability of the Hypothesis on observing the Evidence.  This is the unknown measure that is inferred from the following likelihoods:

* $$P(H)$$ is the prior probability which tell us the likelihood of the Hypothesis before the Evidence is observed.

* $$ P(E \mid H) $$ indicates the compatibility of the Evidence with the given Hypothesis.

* $$P(E)$$ is the marginal Evidence and is fixed for all possible hypotheses being considered. 

One of the ways I often interpret Bayes' rule is via its Information Entropy formulation which presents an equivalent form of the equation terms of Information Content instead of likelihoods.  This provides an alternate, more intuitive view on what goes on when likelihoods are multiplied or divided with eachother within the Bayesian framework.

####Information Theoretic analysis of Bayes’ rule

One way of measuring Information from likelihood (or probability) is via the Entropy measure. Entropy is a fundamental measure of Information content or uncertainty and is defined as

$$
H(A) = -\log_2 P(A)
$$

This transforms a likelihood into a numerical value representing Information Content.  For this analysis the base of the $$\log$$ does not matter so 2 is taken by convention.

To understand what Entropy quantifies we consider two cases:-

* When Entropy is 1 it means:

    1. Probability of occurrence is 1.
    2. Information content is 0 since no further information is gained from observing an event that is certain to happen.
    3. Uncertainty is 0 since no further information is required to confirm whether the event is certain to occur or not.

* When Entropy takes a high value it means:

    1. Probability of occurrence is low (less than 1).
    2. Information content is High since further information is gained from observing an event that is uncertain to happen.
    3. Uncertainty is High since further information is required to confirm whether the event is certain to occur or not.

So in the Information Theoretic sense,

`Amount of Information = Entropy = Amount of Uncertainty`

Having understood this we can now apply Entropy decomposition to Bayes' rule by taking the $$-\log_2$$ of both sides of the equation.

$$
\begin{eqnarray}
-\log_2  P(B  \mid  E)  & = & -\log_2 \left( \frac{ P(B) P(E \mid B)}{  P(E)} \right ) \\
& = & \left(-\log_2 P(B) \right) + \left( -\log_2 P(E \mid B) \right) - \left( - \log_2  P(E) \right ) \\
\end{eqnarray}
$$

Introducing the notation 

$$
H(B \mid E) = -\log_2 \left ( P(B  \mid  E) \right )
$$

$$
H(B)   = -\log_2 \left ( P(B) \right )
$$

$$
H(E \mid B) = -\log_2 \left ( P(E  \mid  B) \right )
$$

$$
H(E)   = -\log_2 \left ( P(E) \right )
$$ 

and some manipulation the expression simplifies to

$$
\begin{eqnarray}
H(B \mid E) & = & H(B) + H(E \mid B) - H(E) \\
       & = & H(B) - \left( H(E) -H(E \mid B) \right) \\
       & = & H(B) - I(E,B)  \\
\end{eqnarray}
$$

which is the Information Theoretic formulation of Bayes' Rule. 

$$I(E,B) =  H(E) -H(E \mid B) $$ has a special meaning as we shall see, but the rest of the terms are all Entropy measures:

* $$H(B)$$ - The amount of uncertainty in the Hypothesis before observing the Evidence.

* $$I(E, B)$$ - Is introduced to denote $$ H(E) -H(E \mid B) $$ and is referred to as the Mutual Information (or Mutual Uncertainty).  This measure the amount of uncertainty shared by both the Hypothesis and Evidence.  It tells us how much knowing the Evidence conveys uncertainty in the Hypothesis and vice versa.  So the higher $$I(E, B)$$ is, the more information (or uncertainty) they convey about each-other.

* $$H(B \mid E)$$ - The amount of uncertainty in the Hypothesis on observing the Evidence.  It tells us the net effect of evidential information $$I(E,B)$$ on the prior information $$H(B)$$.  If the Evidence does not convey any information about the Hypothesis then $$I(E,B)=0$$ and the uncertainty in Hypothesis $$H(B)$$ is not reduced.  But as more information is conveyed by the Evidence then $$I(E,B)$$ becomes larger and effectively reduces uncertainty in Hypothesis $$H(B)$$.

Bayesian inference tells us that:

`posterior information = prior information - evidential information`

or put in a more elaborate way

**_Uncertainty in Hypotheses on observing the Evidence = Prior uncertainty in Hypothesis - Amount of uncertainty in the Hypothesis conveyed by the Evidence_**

Therefore the role of Bayesian inference is to reduce uncertainty in Hypothesis as new Evidence is acquired.


####In Summary:

* Information Entropy provides an alternative way of looking at Bayesian Inference by transforming probability measures into information measures.

* **The role of Bayesian inference is to reduce uncertainty in Hypothesis as new Evidence is acquired.**

* Information Theoretic Bayesian Inference can be written as $$H(B \mid E) =  H(B) - I(E,B)$$

* $$I(B, E) = 0$$ if and only if Evidence and Hypothesis are independent.  That is, they do not convey any information about each other if there is no link between them.

* The technique can be applied to other systems or algorithms that use some form of Bayesian inspired methodology.

